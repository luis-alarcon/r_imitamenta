{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Project Imitamenta</h1>\n",
    "<h2>Protein imitation in Dengue </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Abstract</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Introduction</h3>\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ol>\n",
    "<li><h4>Dengue: A Clinical Apporach</h4></li>\n",
    "    <p>Dengue Fever is a deadly disease caused by the dengue fever virus.  It is one of the most widely spread mosquito-borne diseases (WHO and HealthMap.org, 1997). According to the World Health Organization (WHO, 2012), around 40 % of the world population is at risk of contracting dengue, especially in the tropical and subtropical regions (WHO and HealthMap.org, 1997) (Fig 1.1).  It is estimated that the rate of dengue infection might be as high as 100 million cases annually and about 500,000 per year require hospitalization (Halstead et al., 2007; WHO, 2012).</p>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import of pakcages used in the project\n",
    "import pandas as pd #Pandas are really useful for fast dataframe analysis\n",
    "import numpy \n",
    "import glob\n",
    "import requests\n",
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "import pypdb\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Firstly, we will retrieve the search query with the following parameters from uniprot\n",
    "# Taxonomy: 12637, dengue virus\n",
    "# Format = Tibular\n",
    "# Limit = 10000 \n",
    "# columns: ID, protein name and status \n",
    "url=\"https://www.uniprot.org/uniprot/?query=taxonomy:12637&format=tab&sort=score&columns=id,protein%20names,reviewed\"\n",
    "\n",
    "#We store the data in the url into a variable \n",
    "c=pd.read_csv(url, \"\\t\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will separate the data into 2 variables and transform \n",
    "# them into dataframe in numpy\n",
    "\n",
    "unreviewed_uniprot_dengue = c.loc[c['Status'] == \"unreviewed\"] \n",
    "reviewed_uniprot_dengue = c.loc[c['Status'] == \"reviewed\"] \n",
    "\n",
    "df_unreviewed_uniprot_dengue = pd.DataFrame(unreviewed_uniprot_dengue)\n",
    "df_reviewed_uniprot_dengue = pd.DataFrame(reviewed_uniprot_dengue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"./datasets/dengue_uniprot/uniprot_dengue_list_reviewed.csv\"\n",
    "df_unreviewed_uniprot_dengue.to_csv(path, index=False, compression='gzip')\n",
    "path = \"./datasets/dengue_uniprot/uniprot_dengue_list_unreviewed.csv\"\n",
    "df_reviewed_uniprot_dengue.to_csv(path, index=False, compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will upload the dataset from cath3d with the sequence datam\n",
    "# ftp://orengoftp.biochem.ucl.ac.uk/cath/releases/latest-release/sequence-data/cath-uniprot-annotations.tsv.gz\n",
    "df_cath = pd.read_csv('./datasets/cath_uniprot/cath-uniprot-annotations.tsv',delimiter=\"\\t\", chunksize=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uniprot_to_pdb(code):\n",
    "    chunksize= 10**6 # We choose a chunk size of a million entries\n",
    "    previous = False # This variable allows to identify if matching entries were found in a previous chunk\n",
    "    for chunk in pd.read_csv('./datasets/cath_uniprot/cath-uniprot-annotations.tsv',delimiter=\"\\t\", chunksize=chunksize):\n",
    "        temp = chunk.loc[chunk[\"# UNIPROT_ACC\"] == code]\n",
    "        if not temp.empty: # check if the dataset is no empty\n",
    "            if previous == False: # if no match is found in a previous chunk\n",
    "                df_code = temp[['# UNIPROT_ACC','MODEL_MATCH', 'BOUNDARIES','SUPERFAMILY']].copy().reset_index(drop=True)\n",
    "                df_code[\"PDB\"] = df_code[\"MODEL_MATCH\"].str[:4]\n",
    "                df_cath_temp = pd.DataFrame(columns=df_code.columns)\n",
    "                previous = True\n",
    "            else: # if a match is found in a previous chunk\n",
    "                df_code = temp[['# UNIPROT_ACC','MODEL_MATCH', 'BOUNDARIES','SUPERFAMILY']].copy().reset_index(drop=True)\n",
    "                df_code[\"PDB\"] = df_code[\"MODEL_MATCH\"].str[:4]\n",
    "                df_cath_temp = pd.concat([df_cath_temp,df_code])\n",
    "                print(df_code)\n",
    "        else: # check if temp is empty\n",
    "            if previous == False: # if temp is empty and no matches found in a the previous chunk\n",
    "                continue\n",
    "            else: # if there was a match found in a previous chunk\n",
    "                if df_cath_temp.empty: # if df_cath is empty we return the df_code\n",
    "                    path = \"./datasets/cath_uniprot/\"+code+\".csv\"\n",
    "                    df_code.to_csv(path, index=False, compression='gzip')\n",
    "                    return df_code\n",
    "                else: # if df_cath is not empty we return df_cath\n",
    "                    path = \"./datasets/cath_uniprot/\"+code+\".csv\"\n",
    "                    df_cath_temp.to_csv(path, index=False, compression='gzip')\n",
    "                    return df_cath_temp\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gathering PDB models for the Uniprot codes found for dengue\n",
    "df_cath = pd.DataFrame() # empty dataframe that will store all the data gathered\n",
    "for uniprot_code in df_reviewed_uniprot_dengue[\"Entry\"]:\n",
    "    a= uniprot_to_pdb(uniprot_code) # we store the results in a temporary variable called a\n",
    "    if not df_cath.empty: # if df_cath is not empty we concat a and df_cath\n",
    "            df_cath = pd.concat([df_cath,a])\n",
    "    else: # if df_cath is empty we store a into df_cath\n",
    "        df_cath=a\n",
    "df_cath = df_cath.reset_index(drop=True)\n",
    "path = \"./datasets/cath_uniprot/uniprot_to_pdb_total.csv\"\n",
    "df_cath.to_csv(path, index=False, compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_MOL_des(pdb_name,uniprot_name): # function that finds the Mol description\n",
    "    pdb = pypdb.describe_pdb(pdb_name)\n",
    "    A=[] # temporary list for related pdb\n",
    "    B=[] # temporary list for details of related pdb\n",
    "    if 'relatedPDB' in pdb: # if relatedPDB is in pdb\n",
    "        temp = pdb[\"relatedPDB\"]\n",
    "        listORdict = isinstance(temp, list)\n",
    "        #if temp is a dict\n",
    "        if not listORdict:\n",
    "            l_key = list(temp)\n",
    "            A.append(temp[l_key[0]])\n",
    "            if temp[l_key[1]]:\n",
    "                #a non-empty variable\n",
    "                B.append((temp[l_key[1]]))\n",
    "            else:\n",
    "            #an empty variable\n",
    "                B.append(\"None\")\n",
    "        #If temp is a list\n",
    "        else:\n",
    "            for i in range(len(temp)):\n",
    "                l_key = list(temp[i])\n",
    "                A.append(temp[i][l_key[0]])\n",
    "                if temp[i][l_key[1]]:\n",
    "                    #a non-empty variable\n",
    "                    B.append((temp[i][l_key[1]]))\n",
    "                else:\n",
    "                    #an empty variable\n",
    "                    B.append(None)\n",
    "    else: # if no related PDB is available\n",
    "        A.append(None)\n",
    "        B.append(None)\n",
    "    pdb.pop('relatedPDB',None) # we remove relatedPDB key from pdb\n",
    "    pdb[\"uniprot_code\"]=uniprot_name # we store uniprot code\n",
    "    pdb[\"related_pdb\"]= A \n",
    "    pdb[\"ralated_pdb_details\"] = B\n",
    "    file_name = uniprot_name+\"-\"+pdb_name\n",
    "    pdb_related = pd.DataFrame.from_dict(pdb)\n",
    "    path = \"./datasets/pdb_descriptions/\"+file_name+\".csv\"\n",
    "    pdb_related.to_csv(path, index=False, compression='gzip')\n",
    "    return pdb_related\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:5: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "df_pdb = pd.DataFrame() # new dataframe for the pdb files\n",
    "for i in  range(len(df_cath[\"MODEL_MATCH\"])):\n",
    "    a= find_MOL_des(df_cath[\"MODEL_MATCH\"][i],df_cath[\"# UNIPROT_ACC\"][i])\n",
    "    if not df_pdb.empty:\n",
    "        df_pdb = pd.concat([df_pdb, a],ignore_index=True)\n",
    "    else:\n",
    "        df_pdb=a.copy()\n",
    "\n",
    "df_pdb = df_pdb.reset_index(drop=True)\n",
    "path = \"./datasets/pdb_descriptions/pdb_description_total.csv\"\n",
    "df_pdb.to_csv(path, index=False, compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Organizing the data into CATH superfamilies\n",
    "dengue_superfamilies = df_cath[\"SUPERFAMILY\"].unique()\n",
    "#store df_cath by superfamilies\n",
    "for sf in dengue_superfamilies:\n",
    "    df_superfamilies = df_cath.loc[df_cath[\"SUPERFAMILY\"] == sf]\n",
    "    path = \"./datasets/info_superfamily/\"+sf+\".csv\"\n",
    "    df_superfamilies.to_csv(path, index=False, compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading irefindex dataset\n",
    "df_temp_mitb = pd.read_csv('./datasets/info_superfamily/All.mitab.01-22-2018.txt', delimiter=\"\\t\", chunksize = 100000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#uidA                                                       uniprotkb:P16070\n",
      "uidB                                                    uniprotkb:A0A024RDE2\n",
      "altA                       entrezgene/locuslink:960|refseq:NP_000601|unip...\n",
      "altB                       entrezgene/locuslink:6696|refseq:NP_001035147|...\n",
      "aliasA                     hgnc:CD44|uniprotkb:CD44_HUMAN|crogid:QOb28rF7...\n",
      "aliasB                     hgnc:SPP1|uniprotkb:A0A024RDE2_HUMAN|uniprotkb...\n",
      "method                            psi-mi:\"MI:0813\"(proximity ligation assay)\n",
      "author                                                                     -\n",
      "pmids                                                        pubmed:20549562\n",
      "taxa                                                taxid:9606(Homo sapiens)\n",
      "taxb                                                taxid:9606(Homo sapiens)\n",
      "interactionType                       psi-mi:\"MI:0915\"(physical association)\n",
      "sourcedb                                                   MI:0917(matrixdb)\n",
      "interactionIdentifier      matrixdb:P10451__P16070_20549562_IntAct_1|rigi...\n",
      "confidence                                             hpr:130128|lpr:1|np:3\n",
      "expansion                                                               none\n",
      "biological_role_A                                       MI:0000(unspecified)\n",
      "biological_role_B                                       MI:0000(unspecified)\n",
      "experimental_role_A                                     MI:0000(unspecified)\n",
      "experimental_role_B                                     MI:0000(unspecified)\n",
      "interactor_type_A                                           MI:0326(protein)\n",
      "interactor_type_B                                           MI:0326(protein)\n",
      "xrefs_A                                                                    -\n",
      "xrefs_B                                                                    -\n",
      "xrefs_Interaction                                                          -\n",
      "Annotations_A                                                              -\n",
      "Annotations_B                                                              -\n",
      "Annotations_Interaction                                                    -\n",
      "Host_organism_taxid                                                        -\n",
      "parameters_Interaction                                                     -\n",
      "Creation_date                                                     2018-01-22\n",
      "Update_date                                                       2018-01-22\n",
      "Checksum_A                             rogid:QOb28rF7/ryqfz/ylJFTyL3aoAc9606\n",
      "Checksum_B                             rogid:a1xqyCMAIQpBwLFBbfKN7R+7K3M9606\n",
      "Checksum_Interaction                       rigid:+DolgP4A7i7Y60ozZE2Y6epI39Q\n",
      "Negative                                                               False\n",
      "OriginalReferenceA                                          uniprotkb:P16070\n",
      "OriginalReferenceB                                          uniprotkb:P10451\n",
      "FinalReferenceA                                             uniprotkb:P16070\n",
      "FinalReferenceB                                             uniprotkb:P10451\n",
      "MappingScoreA                                                              P\n",
      "MappingScoreB                                                              P\n",
      "irogida                                                              3739030\n",
      "irogidb                                                              1001745\n",
      "irigid                                                                619679\n",
      "crogida                                      QOb28rF7/ryqfz/ylJFTyL3aoAc9606\n",
      "crogidb                                      a1xqyCMAIQpBwLFBbfKN7R+7K3M9606\n",
      "crigid                                           +DolgP4A7i7Y60ozZE2Y6epI39Q\n",
      "icrogida                                                             3739030\n",
      "icrogidb                                                             1001745\n",
      "icrigid                                                               619679\n",
      "imex_id                                                                    -\n",
      "edgetype                                                                   X\n",
      "numParticipants                                                            2\n",
      "Name: 0, dtype: object\n",
      "------------------------- Values -------------------------\n",
      "['uniprotkb:P16070' 'uniprotkb:A0A024RDE2'\n",
      " 'entrezgene/locuslink:960|refseq:NP_000601|uniprotkb:CD44_HUMAN|rogid:QOb28rF7/ryqfz/ylJFTyL3aoAc9606|irogid:3739030'\n",
      " 'entrezgene/locuslink:6696|refseq:NP_001035147|uniprotkb:A0A024RDE2|rogid:a1xqyCMAIQpBwLFBbfKN7R+7K3M9606|irogid:1001745'\n",
      " 'hgnc:CD44|uniprotkb:CD44_HUMAN|crogid:QOb28rF7/ryqfz/ylJFTyL3aoAc9606|icrogid:3739030'\n",
      " 'hgnc:SPP1|uniprotkb:A0A024RDE2_HUMAN|uniprotkb:OSTP_HUMAN|crogid:a1xqyCMAIQpBwLFBbfKN7R+7K3M9606|icrogid:1001745'\n",
      " 'psi-mi:\"MI:0813\"(proximity ligation assay)' '-' 'pubmed:20549562'\n",
      " 'taxid:9606(Homo sapiens)' 'taxid:9606(Homo sapiens)'\n",
      " 'psi-mi:\"MI:0915\"(physical association)' 'MI:0917(matrixdb)'\n",
      " 'matrixdb:P10451__P16070_20549562_IntAct_1|rigid:+DolgP4A7i7Y60ozZE2Y6epI39Q|edgetype:X'\n",
      " 'hpr:130128|lpr:1|np:3' 'none' 'MI:0000(unspecified)'\n",
      " 'MI:0000(unspecified)' 'MI:0000(unspecified)' 'MI:0000(unspecified)'\n",
      " 'MI:0326(protein)' 'MI:0326(protein)' '-' '-' '-' '-' '-' '-' '-' '-'\n",
      " '2018-01-22' '2018-01-22' 'rogid:QOb28rF7/ryqfz/ylJFTyL3aoAc9606'\n",
      " 'rogid:a1xqyCMAIQpBwLFBbfKN7R+7K3M9606'\n",
      " 'rigid:+DolgP4A7i7Y60ozZE2Y6epI39Q' False 'uniprotkb:P16070'\n",
      " 'uniprotkb:P10451' 'uniprotkb:P16070' 'uniprotkb:P10451' 'P' 'P' 3739030\n",
      " 1001745 619679 'QOb28rF7/ryqfz/ylJFTyL3aoAc9606'\n",
      " 'a1xqyCMAIQpBwLFBbfKN7R+7K3M9606' '+DolgP4A7i7Y60ozZE2Y6epI39Q' 3739030\n",
      " 1001745 619679 '-' 'X' 2]\n",
      "54\n"
     ]
    }
   ],
   "source": [
    "# make the \n",
    "for chunk in df_temp_mitb:\n",
    "    chunk=chunk.reset_index(drop=True)\n",
    "    print(chunk.loc[0])    \n",
    "    print(\"------------------------- Values -------------------------\")\n",
    "    for values in chunk.values:\n",
    "        print(values)\n",
    "        print(len(values))\n",
    "        break\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#uidA\n",
      "uidB\n",
      "altA\n",
      "altB\n",
      "aliasA\n",
      "aliasB\n",
      "method\n",
      "author\n",
      "pmids\n",
      "taxa\n",
      "taxb\n",
      "interactionType\n",
      "sourcedb\n",
      "interactionIdentifier\n",
      "confidence\n",
      "0        hpr\n",
      "1        hpr\n",
      "2        hpr\n",
      "3        hpr\n",
      "4        hpr\n",
      "5        hpr\n",
      "6        hpr\n",
      "7        hpr\n",
      "8        hpr\n",
      "9        hpr\n",
      "10       hpr\n",
      "11       hpr\n",
      "12       hpr\n",
      "13       hpr\n",
      "14       hpr\n",
      "15       hpr\n",
      "16       hpr\n",
      "17       hpr\n",
      "18       hpr\n",
      "19       hpr\n",
      "20       hpr\n",
      "21       hpr\n",
      "22       hpr\n",
      "23       hpr\n",
      "24       hpr\n",
      "25       hpr\n",
      "26       hpr\n",
      "27       hpr\n",
      "28       hpr\n",
      "29       hpr\n",
      "        ... \n",
      "99970    hpr\n",
      "99971    hpr\n",
      "99972    hpr\n",
      "99973    hpr\n",
      "99974    hpr\n",
      "99975    hpr\n",
      "99976    hpr\n",
      "99977    hpr\n",
      "99978    hpr\n",
      "99979    hpr\n",
      "99980    hpr\n",
      "99981    hpr\n",
      "99982    hpr\n",
      "99983    hpr\n",
      "99984    hpr\n",
      "99985    hpr\n",
      "99986    hpr\n",
      "99987    hpr\n",
      "99988    hpr\n",
      "99989    hpr\n",
      "99990    hpr\n",
      "99991    hpr\n",
      "99992    hpr\n",
      "99993    hpr\n",
      "99994    hpr\n",
      "99995    hpr\n",
      "99996    hpr\n",
      "99997    hpr\n",
      "99998    hpr\n",
      "99999    hpr\n",
      "Name: 0, Length: 100000, dtype: object\n",
      "0        lpr\n",
      "1        lpr\n",
      "2        lpr\n",
      "3        lpr\n",
      "4        lpr\n",
      "5        lpr\n",
      "6        lpr\n",
      "7        lpr\n",
      "8        lpr\n",
      "9        lpr\n",
      "10       lpr\n",
      "11       lpr\n",
      "12       lpr\n",
      "13       lpr\n",
      "14       lpr\n",
      "15       lpr\n",
      "16       lpr\n",
      "17       lpr\n",
      "18       lpr\n",
      "19       lpr\n",
      "20       lpr\n",
      "21       lpr\n",
      "22       lpr\n",
      "23       lpr\n",
      "24       lpr\n",
      "25       lpr\n",
      "26       lpr\n",
      "27       lpr\n",
      "28       lpr\n",
      "29       lpr\n",
      "        ... \n",
      "99970    lpr\n",
      "99971    lpr\n",
      "99972    lpr\n",
      "99973    lpr\n",
      "99974    lpr\n",
      "99975    lpr\n",
      "99976    lpr\n",
      "99977    lpr\n",
      "99978    lpr\n",
      "99979    lpr\n",
      "99980    lpr\n",
      "99981    lpr\n",
      "99982    lpr\n",
      "99983    lpr\n",
      "99984    lpr\n",
      "99985    lpr\n",
      "99986    lpr\n",
      "99987    lpr\n",
      "99988    lpr\n",
      "99989    lpr\n",
      "99990    lpr\n",
      "99991    lpr\n",
      "99992    lpr\n",
      "99993    lpr\n",
      "99994    lpr\n",
      "99995    lpr\n",
      "99996    lpr\n",
      "99997    lpr\n",
      "99998    lpr\n",
      "99999    lpr\n",
      "Name: 1, Length: 100000, dtype: object\n",
      "0        np\n",
      "1        np\n",
      "2        np\n",
      "3        np\n",
      "4        np\n",
      "5        np\n",
      "6        np\n",
      "7        np\n",
      "8        np\n",
      "9        np\n",
      "10       np\n",
      "11       np\n",
      "12       np\n",
      "13       np\n",
      "14       np\n",
      "15       np\n",
      "16       np\n",
      "17       np\n",
      "18       np\n",
      "19       np\n",
      "20       np\n",
      "21       np\n",
      "22       np\n",
      "23       np\n",
      "24       np\n",
      "25       np\n",
      "26       np\n",
      "27       np\n",
      "28       np\n",
      "29       np\n",
      "         ..\n",
      "99970    np\n",
      "99971    np\n",
      "99972    np\n",
      "99973    np\n",
      "99974    np\n",
      "99975    np\n",
      "99976    np\n",
      "99977    np\n",
      "99978    np\n",
      "99979    np\n",
      "99980    np\n",
      "99981    np\n",
      "99982    np\n",
      "99983    np\n",
      "99984    np\n",
      "99985    np\n",
      "99986    np\n",
      "99987    np\n",
      "99988    np\n",
      "99989    np\n",
      "99990    np\n",
      "99991    np\n",
      "99992    np\n",
      "99993    np\n",
      "99994    np\n",
      "99995    np\n",
      "99996    np\n",
      "99997    np\n",
      "99998    np\n",
      "99999    np\n",
      "Name: 2, Length: 100000, dtype: object\n"
     ]
    }
   ],
   "source": [
    "chunk=chunk.reset_index(drop=True)\n",
    "l_key = chunk.columns\n",
    "d = dict.fromkeys(l_key, [])\n",
    "temp = {}\n",
    "for column, values in chunk.iteritems():\n",
    "    print(column)\n",
    "    #process uidA\n",
    "    if column == \"#uidA\":\n",
    "        temp['a_type_id'], temp['a_id'] = values.str.split(':', 1).str\n",
    "    #process uidB\n",
    "    if column == \"uidB\":\n",
    "        temp['b_type_id'], temp['b_id'] = values.str.split(':', 1).str\n",
    "    \n",
    "    if column == \"confidence\":\n",
    "        df_temp_confidence = values.str.split('|', -1,expand=True)\n",
    "        #.reset_index(drop=True)\n",
    "        for column in df_temp_confidence:\n",
    "            a1,b1= df_temp_confidence[column].str.split(':', 1).str\n",
    "            print(a1)\n",
    "            break\n",
    "        break\n",
    "    if column ==\"expansion\":\n",
    "        values[values == \"none\"] = None\n",
    "        temp[\"expansion\"] = values\n",
    "    if column ==\"biological_role_A\":\n",
    "        a1, b1 = values.str.split(':', 1).str # separate string by :\n",
    "        temp[\"biological_role_a_id\"] = b1.str.replace(r\"\\(.*\\)\",\"\") # extract text outside the parenthesis\n",
    "        temp[\"biological_role_a_name\"]=b1.str.replace(r'[\\(\\)\\d]+', '')# extract text inside parenthesis\n",
    "    if column ==\"biological_role_B\":\n",
    "        a1, b1 = values.str.split(':', 1).str # separate string by :\n",
    "        temp[\"biological_role_b_id\"] = b1.str.replace(r\"\\(.*\\)\",\"\") # extract text outside the parenthesis\n",
    "        temp[\"biological_role_b_name\"]=b1.str.replace(r'[\\(\\)\\d]+', '')# extract text inside parenthesis\n",
    "    if column ==\"experimental_role_A\":\n",
    "        a1, b1 = values.str.split(':', 1).str # separate string by :\n",
    "        temp[\"experimental_role_a_id\"] = b1.str.replace(r\"\\(.*\\)\",\"\") # extract text outside the parenthesis\n",
    "        temp[\"experimental_role_a_name\"]=b1.str.replace(r'[\\(\\)\\d]+', '')# extract text inside parenthesis\n",
    "    if column ==\"experimental_role_B\":\n",
    "        a1, b1 = values.str.split(':', 1).str # separate string by :\n",
    "        temp[\"experimental_role_b_id\"] = b1.str.replace(r\"\\(.*\\)\",\"\") # extract text outside the parenthesis\n",
    "        temp[\"experimental_role_b_name\"]=b1.str.replace(r'[\\(\\)\\d]+', '')# extract text inside parenthesis\n",
    "    if column ==\"interactor_type_A\":\n",
    "        a1, b1 = values.str.split(':', 1).str # separate string by :\n",
    "        temp[\"interactor_type_a_id\"] = b1.str.replace(r\"\\(.*\\)\",\"\") # extract text outside the parenthesis\n",
    "        temp[\"interactor_type_a_name\"]=b1.str.replace(r'[\\(\\)\\d]+', '')# extract text inside parenthesis\n",
    "    if column ==\"interactor_type_B\":\n",
    "        a1, b1 = values.str.split(':', 1).str # separate string by :\n",
    "        temp[\"interactor_type_b_id\"] = b1.str.replace(r\"\\(.*\\)\",\"\") # extract text outside the parenthesis\n",
    "        temp[\"interactor_type_b_name\"]=b1.str.replace(r'[\\(\\)\\d]+', '')# extract text inside parenthesis    \n",
    "    if column == \"xrefs_A\":\n",
    "        values[values == \"-\"] = None\n",
    "        temp[\"xrefs_a\"] = values  \n",
    "    if column == \"xrefs_B\":\n",
    "        values[values == \"-\"] = None\n",
    "        temp[\"xrefs_b\"] = values  \n",
    "    if column ==\"xrefs_Interaction\":\n",
    "        values[values == \"-\"] = None\n",
    "        temp[\"xrefs_interaction\"] = values  \n",
    "    if column ==\"Annotations_a\":\n",
    "        values[values == \"-\"] = None\n",
    "        temp[\"annotations_a\"] = values    \n",
    "    if column ==\"Annotations_B\":\n",
    "        values[values == \"-\"] = None\n",
    "        temp[\"annotations_b\"] = values    \n",
    "    if column == \"Annotations_Interaction\":\n",
    "        values[values == \"-\"] = None\n",
    "        temp[\"annotations_interaction\"] = values    \n",
    "    if column ==\"Host_organism_taxid\":\n",
    "        a1, b1 = values.str.split(':', 1).str # separate string by :\n",
    "        temp[\"host_organism_taxid\"] = b1.str.replace(r\"\\(.*\\)\",\"\") # extract text outside the parenthesis\n",
    "        temp[\"host_organism_tax_name\"]=b1.str.replace(r'[\\(\\)\\d]+', '')# extract text inside parenthesis\n",
    "    if column ==\"parameters_Interaction\":\n",
    "        values[values == \"-\"] = None\n",
    "        temp[\"parameters_interaction\"] = values\n",
    "    if column == \"Creation_date\":\n",
    "        temp[\"creation_date\"] = values \n",
    "    if column == \"Update_date\":\n",
    "        temp[\"update_date\"] = values \n",
    "    if column == \"Negative\":\n",
    "        temp[\"negative\"] = values    \n",
    "    if column == \"irogida\":\n",
    "        temp[\"irogida\"] = values \n",
    "    if column == \"irogidb\":\n",
    "        temp[\"irogidb\"] = values \n",
    "    if column == \"irigid\":\n",
    "        temp[\"irigid\"] = values \n",
    "    if column == \"crogida\":\n",
    "        temp[\"crogida\"] = values \n",
    "    if column == \"crogidb\":\n",
    "        temp[\"crogidb\"] = values \n",
    "    if column == \"crigid\":\n",
    "        temp[\"crigid\"] = values    \n",
    "    if column == \"icrogida\":\n",
    "        temp[\"icrigida\"] = values    \n",
    "    if column == \"icrogidb\":\n",
    "        temp[\"icrigidb\"] = values    \n",
    "    if column == \"icrogid\":\n",
    "        temp[\"icrigid\"] = values    \n",
    "    if column == \"imex_id\":\n",
    "        temp[\"imex_id\"] = values\n",
    "    if column == \"numParticipants\":\n",
    "        temp[\"numParticipants\"] = values\n",
    "    #if column == \"altA\":\n",
    "    #    a = str(values[0])\n",
    "    #    b = a.split(\"|\")\n",
    "    #    b_series = pd.Series(b)\n",
    "    #    c,d = b_series.str.split(':', 1).str\n",
    "    #    print(d)\n",
    "    #    break\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change delimeter and add column names\n",
    "ii_columns = ['uidA','uidB','altA','altB','aliasA','aliasB','method','author'\n",
    "              ,'pmids','taxa','taxb','interactionType','sourcedb','interactionIdentifier'\n",
    "              ,'confidence','expansion','biological_role_A','biological_role_B'\n",
    "              ,'experimental_role_A','experimental_role_B','interactor_type_A'\n",
    "              ,'interactor_type_B','xrefs_A','xrefs_B','xrefs_Interaction',\n",
    "              'Annotations_A','Annotations_B','Annotations_Interaction',\n",
    "              'Host_organism_taxid','parameters_Interaction','Creation_date',\n",
    "              'Update_date','Checksum_A','Checksum_B','Checksum_Interaction',\n",
    "              'Negative','OriginalReferenceA','OriginalReferenceB','FinalReferenceA'\n",
    "              ,'FinalReferenceB','MappingScoreA','MappingScoreB','irogida'\n",
    "              ,'irogidb','irigid','crogida','crogidb','crigid',\n",
    "              'icrogida','icrogidb','icrigid','imex_id','edgetype','numParticipants']\n",
    "df_irefindex = pd.read_csv('http://irefindex.org/download/irefindex/data/archive/release_15.0/psi_mitab/MITAB2.6/All.mitab.22012018.txt.zip',skiprows=1,delimiter='\\\\',header=None ,compression='zip',error_bad_lines=False)\n",
    "df_irefindex.columns = ii_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample=pd.read_csv(StringIO(''.join(l.replace('', ',') for l in open('stuff.csv'))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with zipfile.ZipFile('http://irefindex.org/download/irefindex/data/current/psi_mitab/MITAB2.6/All.mitab.22012018.txt.zip') as z:\n",
    "    with z.open('All.mitab.22012018.txt') as f:\n",
    "        for line in f:\n",
    "            print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib3\n",
    "\n",
    "http = urllib3.PoolManager()\n",
    "\n",
    "R = http.request('GET', \"http://irefindex.org/download/irefindex/data/current/psi_mitab/MITAB2.6/All.mitab.22012018.txt.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(R.read)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
