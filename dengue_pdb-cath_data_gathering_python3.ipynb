{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Project Imitamenta</h1>\n",
    "<h2>Protein imitation in Dengue </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Abstract</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Introduction</h3>\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ol>\n",
    "<li><h4>Dengue: A Clinical Apporach</h4></li>\n",
    "    <p>Dengue Fever is a deadly disease caused by the dengue fever virus.  It is one of the most widely spread mosquito-borne diseases (WHO and HealthMap.org, 1997). According to the World Health Organization (WHO, 2012), around 40 % of the world population is at risk of contracting dengue, especially in the tropical and subtropical regions (WHO and HealthMap.org, 1997) (Fig 1.1).  It is estimated that the rate of dengue infection might be as high as 100 million cases annually and about 500,000 per year require hospitalization (Halstead et al., 2007; WHO, 2012).</p>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import of pakcages used in the project\n",
    "import pandas as pd #Pandas are really useful for fast dataframe analysis\n",
    "import numpy \n",
    "import glob\n",
    "import requests\n",
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "import pypdb\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Firstly, we will retrieve the search query with the following parameters from uniprot\n",
    "# Taxonomy: 12637, dengue virus\n",
    "# Format = Tibular\n",
    "# Limit = 10000 \n",
    "# columns: ID, protein name and status \n",
    "url=\"https://www.uniprot.org/uniprot/?query=taxonomy:12637&format=tab&sort=score&columns=id,protein%20names,reviewed\"\n",
    "\n",
    "#We store the data in the url into a variable \n",
    "c=pd.read_csv(url, \"\\t\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will separate the data into 2 variables and transform \n",
    "# them into dataframe in numpy\n",
    "\n",
    "unreviewed_uniprot_dengue = c.loc[c['Status'] == \"unreviewed\"] \n",
    "reviewed_uniprot_dengue = c.loc[c['Status'] == \"reviewed\"] \n",
    "\n",
    "df_unreviewed_uniprot_dengue = pd.DataFrame(unreviewed_uniprot_dengue)\n",
    "df_reviewed_uniprot_dengue = pd.DataFrame(reviewed_uniprot_dengue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"./datasets/dengue_uniprot/uniprot_dengue_list_reviewed.csv\"\n",
    "df_unreviewed_uniprot_dengue.to_csv(path, index=False, compression='gzip')\n",
    "path = \"./datasets/dengue_uniprot/uniprot_dengue_list_unreviewed.csv\"\n",
    "df_reviewed_uniprot_dengue.to_csv(path, index=False, compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Entry                                      Protein names    Status\n",
      "0  Q5UCB8  Genome polyprotein [Cleaved into: Capsid prote...  reviewed\n",
      "1  P27913  Genome polyprotein [Cleaved into: Capsid prote...  reviewed\n",
      "2  Q9WDA6  Genome polyprotein [Cleaved into: Capsid prote...  reviewed\n",
      "3  P27914  Genome polyprotein [Cleaved into: Envelope pro...  reviewed\n",
      "4  Q5UB51  Genome polyprotein [Cleaved into: Capsid prote...  reviewed\n"
     ]
    }
   ],
   "source": [
    "df_unreviewed_uniprot_dengue = pd.read_csv(\"./datasets/dengue_uniprot/uniprot_dengue_list_reviewed.csv\", compression='gzip')\n",
    "df_reviewed_uniprot_dengue = pd.read_csv(\"./datasets/dengue_uniprot/uniprot_dengue_list_unreviewed.csv\", compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will upload the dataset from cath3d with the sequence datam\n",
    "# ftp://orengoftp.biochem.ucl.ac.uk/cath/releases/latest-release/sequence-data/cath-uniprot-annotations.tsv.gz\n",
    "df_cath = pd.read_csv('./datasets/cath_uniprot/cath-uniprot-annotations.tsv',delimiter=\"\\t\", chunksize=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uniprot_to_pdb(code):\n",
    "    chunksize= 10**6 # We choose a chunk size of a million entries\n",
    "    previous = False # This variable allows to identify if matching entries were found in a previous chunk\n",
    "    for chunk in pd.read_csv('./datasets/cath_uniprot/cath-uniprot-annotations.tsv',delimiter=\"\\t\", chunksize=chunksize):\n",
    "        temp = chunk.loc[chunk[\"# UNIPROT_ACC\"] == code]\n",
    "        if not temp.empty: # check if the dataset is no empty\n",
    "            if previous == False: # if no match is found in a previous chunk\n",
    "                df_code = temp[['# UNIPROT_ACC','MODEL_MATCH', 'BOUNDARIES','SUPERFAMILY']].copy().reset_index(drop=True)\n",
    "                df_code[\"PDB\"] = df_code[\"MODEL_MATCH\"].str[:4]\n",
    "                df_cath_temp = pd.DataFrame(columns=df_code.columns)\n",
    "                previous = True\n",
    "            else: # if a match is found in a previous chunk\n",
    "                df_code = temp[['# UNIPROT_ACC','MODEL_MATCH', 'BOUNDARIES','SUPERFAMILY']].copy().reset_index(drop=True)\n",
    "                df_code[\"PDB\"] = df_code[\"MODEL_MATCH\"].str[:4]\n",
    "                df_cath_temp = pd.concat([df_cath_temp,df_code])\n",
    "                print(df_code)\n",
    "        else: # check if temp is empty\n",
    "            if previous == False: # if temp is empty and no matches found in a the previous chunk\n",
    "                continue\n",
    "            else: # if there was a match found in a previous chunk\n",
    "                if df_cath_temp.empty: # if df_cath is empty we return the df_code\n",
    "                    path = \"./datasets/cath_uniprot/\"+code+\".csv\"\n",
    "                    df_code.to_csv(path, index=False, compression='gzip')\n",
    "                    return df_code\n",
    "                else: # if df_cath is not empty we return df_cath\n",
    "                    path = \"./datasets/cath_uniprot/\"+code+\".csv\"\n",
    "                    df_cath_temp.to_csv(path, index=False, compression='gzip')\n",
    "                    return df_cath_temp\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gathering PDB models for the Uniprot codes found for dengue\n",
    "df_cath = pd.DataFrame() # empty dataframe that will store all the data gathered\n",
    "for uniprot_code in df_reviewed_uniprot_dengue[\"Entry\"]:\n",
    "    a= uniprot_to_pdb(uniprot_code) # we store the results in a temporary variable called a\n",
    "    if not df_cath.empty: # if df_cath is not empty we concat a and df_cath\n",
    "            df_cath = pd.concat([df_cath,a])\n",
    "    else: # if df_cath is empty we store a into df_cath\n",
    "        df_cath=a\n",
    "df_cath = df_cath.reset_index(drop=True)\n",
    "path = \"./datasets/cath_uniprot/uniprot_to_pdb_total.csv\"\n",
    "df_cath.to_csv(path, index=False, compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  # UNIPROT_ACC MODEL_MATCH BOUNDARIES    SUPERFAMILY   PDB\n",
      "0        Q5UCB8     5jwhA02  1656-2092    3.40.50.300  5jwh\n",
      "1        Q5UCB8     5jwhA01  1656-2092    3.40.50.300  5jwh\n",
      "2        Q5UCB8     5iz7A05    675-774  1.20.1280.260  5iz7\n",
      "3        Q5UCB8     4x42B00    573-679    2.60.40.350  4x42\n",
      "4        Q5UCB8     4m9fA00  1388-1446    2.40.10.120  4m9f\n"
     ]
    }
   ],
   "source": [
    "df_cath = pd.read_csv(\"./datasets/cath_uniprot/uniprot_to_pdb_total.csv\", compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_MOL_des(pdb_name,uniprot_name): # function that finds the Mol description\n",
    "    pdb = pypdb.describe_pdb(pdb_name)\n",
    "    A=[] # temporary list for related pdb\n",
    "    B=[] # temporary list for details of related pdb\n",
    "    if 'relatedPDB' in pdb: # if relatedPDB is in pdb\n",
    "        temp = pdb[\"relatedPDB\"]\n",
    "        listORdict = isinstance(temp, list)\n",
    "        #if temp is a dict\n",
    "        if not listORdict:\n",
    "            l_key = list(temp)\n",
    "            A.append(temp[l_key[0]])\n",
    "            if temp[l_key[1]]:\n",
    "                #a non-empty variable\n",
    "                B.append((temp[l_key[1]]))\n",
    "            else:\n",
    "            #an empty variable\n",
    "                B.append(\"None\")\n",
    "        #If temp is a list\n",
    "        else:\n",
    "            for i in range(len(temp)):\n",
    "                l_key = list(temp[i])\n",
    "                A.append(temp[i][l_key[0]])\n",
    "                if temp[i][l_key[1]]:\n",
    "                    #a non-empty variable\n",
    "                    B.append((temp[i][l_key[1]]))\n",
    "                else:\n",
    "                    #an empty variable\n",
    "                    B.append(None)\n",
    "    else: # if no related PDB is available\n",
    "        A.append(None)\n",
    "        B.append(None)\n",
    "    pdb.pop('relatedPDB',None) # we remove relatedPDB key from pdb\n",
    "    pdb[\"uniprot_code\"]=uniprot_name # we store uniprot code\n",
    "    pdb[\"related_pdb\"]= A \n",
    "    pdb[\"ralated_pdb_details\"] = B\n",
    "    file_name = uniprot_name+\"-\"+pdb_name\n",
    "    pdb_related = pd.DataFrame.from_dict(pdb)\n",
    "    path = \"./datasets/pdb_descriptions/\"+file_name+\".csv\"\n",
    "    pdb_related.to_csv(path, index=False, compression='gzip')\n",
    "    return pdb_related\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pdb = pd.DataFrame() # new dataframe for the pdb files\n",
    "for i in  range(len(df_cath[\"MODEL_MATCH\"])):\n",
    "    a= find_MOL_des(df_cath[\"MODEL_MATCH\"][i],df_cath[\"# UNIPROT_ACC\"][i])\n",
    "    if not df_pdb.empty:\n",
    "        df_pdb = pd.concat([df_pdb, a],ignore_index=True)\n",
    "    else:\n",
    "        df_pdb=a.copy()\n",
    "\n",
    "df_pdb = df_pdb.reset_index(drop=True)\n",
    "path = \"./datasets/pdb_descriptions/pdb_description_total.csv\"\n",
    "df_pdb.to_csv(path, index=False, compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pdb = pd.read_csv(\"./datasets/pdb_descriptions/pdb_description_total.csv\", compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Organizing the data into CATH superfamilies\n",
    "dengue_superfamilies = df_cath[\"SUPERFAMILY\"].unique()\n",
    "#store df_cath by superfamilies\n",
    "for sf in dengue_superfamilies:\n",
    "    df_superfamilies = df_cath.loc[df_cath[\"SUPERFAMILY\"] == sf]\n",
    "    path = \"./datasets/info_superfamily/\"+sf+\".csv\"\n",
    "    df_superfamilies.to_csv(path, index=False, compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading irefindex dataset\n",
    "df_temp_mitb = pd.read_csv('./datasets/info_superfamily/All.mitab.01-22-2018.txt', delimiter=\"\\t\", chunksize = 100000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#uidA                                                       uniprotkb:P54274\n",
      "uidB                                                        uniprotkb:O00410\n",
      "altA                       entrezgene/locuslink:7013|refseq:NP_059523|uni...\n",
      "altB                       entrezgene/locuslink:3843|uniprotkb:O00410|rog...\n",
      "aliasA                     hgnc:TERF1|uniprotkb:TERF1_HUMAN|crogid:3Tjmp8...\n",
      "aliasB                     hgnc:IPO5|uniprotkb:IPO5_HUMAN|crogid:jBYLvkqy...\n",
      "method                     psi-mi:\"MI:0809\"(bimolecular fluorescence comp...\n",
      "author                                                                     -\n",
      "pmids                                                        pubmed:21044950\n",
      "taxa                                                taxid:9606(Homo sapiens)\n",
      "taxb                                                taxid:9606(Homo sapiens)\n",
      "interactionType                       psi-mi:\"MI:0915\"(physical association)\n",
      "sourcedb                                                    MI:1332(bhf-ucl)\n",
      "interactionIdentifier      intact:EBI-11307583|rigid:SOQY1j5vq9haoYbS04J+...\n",
      "confidence                                            hpr:1112|lpr:1112|np:1\n",
      "expansion                                                               none\n",
      "biological_role_A                                       MI:0000(unspecified)\n",
      "biological_role_B                                       MI:0000(unspecified)\n",
      "experimental_role_A                                     MI:0000(unspecified)\n",
      "experimental_role_B                                     MI:0000(unspecified)\n",
      "interactor_type_A                                           MI:0326(protein)\n",
      "interactor_type_B                                           MI:0326(protein)\n",
      "xrefs_A                                                                    -\n",
      "xrefs_B                                                                    -\n",
      "xrefs_Interaction                                                          -\n",
      "Annotations_A                                                              -\n",
      "Annotations_B                                                              -\n",
      "Annotations_Interaction                                                    -\n",
      "Host_organism_taxid                                                        -\n",
      "parameters_Interaction                                                     -\n",
      "Creation_date                                                     2018-01-22\n",
      "Update_date                                                       2018-01-22\n",
      "Checksum_A                             rogid:3Tjmp8hqEhLBIQqxxWHntpL4hz49606\n",
      "Checksum_B                             rogid:jBYLvkqyYyWAu1TdCVyCMh9ZHKY9606\n",
      "Checksum_Interaction                       rigid:SOQY1j5vq9haoYbS04J+Y3brn/4\n",
      "Negative                                                               False\n",
      "OriginalReferenceA                                          uniprotkb:P54274\n",
      "OriginalReferenceB                                          uniprotkb:O00410\n",
      "FinalReferenceA                                             uniprotkb:P54274\n",
      "FinalReferenceB                                             uniprotkb:O00410\n",
      "MappingScoreA                                                              P\n",
      "MappingScoreB                                                              P\n",
      "irogida                                                              5406538\n",
      "irogidb                                                              2521025\n",
      "irigid                                                               2368953\n",
      "crogida                                      3Tjmp8hqEhLBIQqxxWHntpL4hz49606\n",
      "crogidb                                      jBYLvkqyYyWAu1TdCVyCMh9ZHKY9606\n",
      "crigid                                           SOQY1j5vq9haoYbS04J+Y3brn/4\n",
      "icrogida                                                             5406538\n",
      "icrogidb                                                             2521025\n",
      "icrigid                                                              2368953\n",
      "imex_id                                                                    -\n",
      "edgetype                                                                   X\n",
      "numParticipants                                                            2\n",
      "Name: 0, dtype: object\n",
      "------------------------- Values -------------------------\n",
      "['uniprotkb:P54274' 'uniprotkb:O00410'\n",
      " 'entrezgene/locuslink:7013|refseq:NP_059523|uniprotkb:P54274|rogid:3Tjmp8hqEhLBIQqxxWHntpL4hz49606|irogid:5406538'\n",
      " 'entrezgene/locuslink:3843|uniprotkb:O00410|rogid:jBYLvkqyYyWAu1TdCVyCMh9ZHKY9606|irogid:2521025'\n",
      " 'hgnc:TERF1|uniprotkb:TERF1_HUMAN|crogid:3Tjmp8hqEhLBIQqxxWHntpL4hz49606|icrogid:5406538'\n",
      " 'hgnc:IPO5|uniprotkb:IPO5_HUMAN|crogid:jBYLvkqyYyWAu1TdCVyCMh9ZHKY9606|icrogid:2521025'\n",
      " 'psi-mi:\"MI:0809\"(bimolecular fluorescence complementation)' '-'\n",
      " 'pubmed:21044950' 'taxid:9606(Homo sapiens)' 'taxid:9606(Homo sapiens)'\n",
      " 'psi-mi:\"MI:0915\"(physical association)' 'MI:1332(bhf-ucl)'\n",
      " 'intact:EBI-11307583|rigid:SOQY1j5vq9haoYbS04J+Y3brn/4|edgetype:X'\n",
      " 'hpr:1112|lpr:1112|np:1' 'none' 'MI:0000(unspecified)'\n",
      " 'MI:0000(unspecified)' 'MI:0000(unspecified)' 'MI:0000(unspecified)'\n",
      " 'MI:0326(protein)' 'MI:0326(protein)' '-' '-' '-' '-' '-' '-' '-' '-'\n",
      " '2018-01-22' '2018-01-22' 'rogid:3Tjmp8hqEhLBIQqxxWHntpL4hz49606'\n",
      " 'rogid:jBYLvkqyYyWAu1TdCVyCMh9ZHKY9606'\n",
      " 'rigid:SOQY1j5vq9haoYbS04J+Y3brn/4' False 'uniprotkb:P54274'\n",
      " 'uniprotkb:O00410' 'uniprotkb:P54274' 'uniprotkb:O00410' 'P' 'P' 5406538\n",
      " 2521025 2368953 '3Tjmp8hqEhLBIQqxxWHntpL4hz49606'\n",
      " 'jBYLvkqyYyWAu1TdCVyCMh9ZHKY9606' 'SOQY1j5vq9haoYbS04J+Y3brn/4' 5406538\n",
      " 2521025 2368953 '-' 'X' 2]\n",
      "54\n"
     ]
    }
   ],
   "source": [
    "# make the \n",
    "for chunk in df_temp_mitb:\n",
    "    chunk=chunk.reset_index(drop=True)\n",
    "    print(chunk.loc[0])    \n",
    "    print(\"------------------------- Values -------------------------\")\n",
    "    for values in chunk.values:\n",
    "        print(values)\n",
    "        print(len(values))\n",
    "        break\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#uidA\n",
      "uidB\n",
      "altA\n",
      "altB\n",
      "aliasA\n",
      "aliasB\n",
      "method\n",
      "author\n",
      "pmids\n",
      "taxa\n",
      "taxb\n",
      "interactionType\n",
      "sourcedb\n",
      "interactionIdentifier\n",
      "['intact' 'bind' 'biogrid' 'pubmed' 'dip' 'hprd' 'innatedb' 'InnateDB'\n",
      " 'efo' 'matrixdb' 'mips' 'mpidb' 'mppi' '-' 'pdbe' 'virhostnet-rid' 'pdb'\n",
      " 'emdb' 'protein ontology' 'chembl target' 'reactome' 'intenz'\n",
      " 'InnateDB Allergy' 'orphanet']\n",
      "36978    1emu\n",
      "36979    1emu\n",
      "36980    1emu\n",
      "36981    1emu\n",
      "45411    2X1G\n",
      "45412    2X1G\n",
      "45413    2X1G\n",
      "50012    4C8Q\n",
      "50013    4C8Q\n",
      "50014    4C8Q\n",
      "50015    4C8Q\n",
      "50016    4C8Q\n",
      "50017    4C8Q\n",
      "50018    4C8Q\n",
      "50019    4C8Q\n",
      "54600    2j0s\n",
      "54601    2j0s\n",
      "54602    2j0s\n",
      "54603    2j0s\n",
      "56693    4C3J\n",
      "56694    4C3J\n",
      "56695    4C3J\n",
      "56696    4C3J\n",
      "56697    4C3J\n",
      "56698    4C3J\n",
      "56699    4C3J\n",
      "56700    4C3J\n",
      "56701    4C3J\n",
      "56702    4C3J\n",
      "56703    4C3J\n",
      "56704    4C3J\n",
      "56705    4C3J\n",
      "56706    4C3J\n",
      "66590    1EV2\n",
      "66591    1EV2\n",
      "66592    1EV2\n",
      "73237    4jbw\n",
      "73238    4jbw\n",
      "73239    4jbw\n",
      "73240    4jbw\n",
      "85365    3io8\n",
      "91076    4BUJ\n",
      "91077    4BUJ\n",
      "91078    4BUJ\n",
      "Name: 1, dtype: object\n"
     ]
    }
   ],
   "source": [
    "chunk=chunk.reset_index(drop=True)\n",
    "l_key = chunk.columns\n",
    "d = dict.fromkeys(l_key, [])\n",
    "temp = {}\n",
    "for column, values in chunk.iteritems():\n",
    "    print(column)\n",
    "    #process uidA\n",
    "    if column == \"#uidA\":\n",
    "        temp['a_type_id'], temp['a_id'] = values.str.split(':', 1).str\n",
    "    #process uidB\n",
    "    if column == \"uidB\":\n",
    "        temp['b_type_id'], temp['b_id'] = values.str.split(':', 1).str\n",
    "    \n",
    "    #interactionIdentifier\n",
    "    if column == \"interactionIdentifier\":\n",
    "        df_temp_interaction_id = values.str.split('|', -1,expand=True)\n",
    "        for c in df_temp_interaction_id:\n",
    "            a1 = df_temp_interaction_id[c].str.split(':', -1,expand=True)\n",
    "            a1.drop(2, axis=1, inplace=True)\n",
    "            #print(a1[1].loc[a1[0]==\"pdb\"])\n",
    "            keys = a1[0].unique()\n",
    "            break\n",
    "        break\n",
    "    #revise anything bellow!\n",
    "    if column == \"confidence\":\n",
    "        df_temp_confidence = values.str.split('|', -1,expand=True)\n",
    "        #.reset_index(drop=True)\n",
    "        for c in df_temp_confidence:\n",
    "            a1= df_temp_confidence[c].str.split(':', -1,expand=True)\n",
    "            temp_keys = a1[0].unique()\n",
    "            keys = a1[0].unique()\n",
    "            keys[keys==\"-\"] = None\n",
    "            keys[keys != None] = keys[keys != None] +\"_code\"\n",
    "            for i in range(len(temp_keys)):\n",
    "                temp[keys[0]] = a1[1].loc[a1[0]==str(temp_keys[i])]\n",
    "                if temp_keys[i] == \"-\":\n",
    "                    continue\n",
    "    if column ==\"expansion\":\n",
    "        values[values == \"none\"] = None\n",
    "        temp[\"expansion\"] = values\n",
    "    if column ==\"biological_role_A\":\n",
    "        a1, b1 = values.str.split(':', 1).str # separate string by :\n",
    "        temp[\"biological_role_a_id\"] = b1.str.replace(r\"\\(.*\\)\",\"\") # extract text outside the parenthesis\n",
    "        temp[\"biological_role_a_name\"]=b1.str.replace(r'[\\(\\)\\d]+', '')# extract text inside parenthesis\n",
    "    if column ==\"biological_role_B\":\n",
    "        a1, b1 = values.str.split(':', 1).str # separate string by :\n",
    "        temp[\"biological_role_b_id\"] = b1.str.replace(r\"\\(.*\\)\",\"\") # extract text outside the parenthesis\n",
    "        temp[\"biological_role_b_name\"]=b1.str.replace(r'[\\(\\)\\d]+', '')# extract text inside parenthesis\n",
    "    if column ==\"experimental_role_A\":\n",
    "        a1, b1 = values.str.split(':', 1).str # separate string by :\n",
    "        temp[\"experimental_role_a_id\"] = b1.str.replace(r\"\\(.*\\)\",\"\") # extract text outside the parenthesis\n",
    "        temp[\"experimental_role_a_name\"]=b1.str.replace(r'[\\(\\)\\d]+', '')# extract text inside parenthesis\n",
    "    if column ==\"experimental_role_B\":\n",
    "        a1, b1 = values.str.split(':', 1).str # separate string by :\n",
    "        temp[\"experimental_role_b_id\"] = b1.str.replace(r\"\\(.*\\)\",\"\") # extract text outside the parenthesis\n",
    "        temp[\"experimental_role_b_name\"]=b1.str.replace(r'[\\(\\)\\d]+', '')# extract text inside parenthesis\n",
    "    if column ==\"interactor_type_A\":\n",
    "        a1, b1 = values.str.split(':', 1).str # separate string by :\n",
    "        temp[\"interactor_type_a_id\"] = b1.str.replace(r\"\\(.*\\)\",\"\") # extract text outside the parenthesis\n",
    "        temp[\"interactor_type_a_name\"]=b1.str.replace(r'[\\(\\)\\d]+', '')# extract text inside parenthesis\n",
    "    if column ==\"interactor_type_B\":\n",
    "        a1, b1 = values.str.split(':', 1).str # separate string by :\n",
    "        temp[\"interactor_type_b_id\"] = b1.str.replace(r\"\\(.*\\)\",\"\") # extract text outside the parenthesis\n",
    "        temp[\"interactor_type_b_name\"]=b1.str.replace(r'[\\(\\)\\d]+', '')# extract text inside parenthesis    \n",
    "    if column == \"xrefs_A\":\n",
    "        values[values == \"-\"] = None\n",
    "        temp[\"xrefs_a\"] = values  \n",
    "    if column == \"xrefs_B\":\n",
    "        values[values == \"-\"] = None\n",
    "        temp[\"xrefs_b\"] = values  \n",
    "    if column ==\"xrefs_Interaction\":\n",
    "        values[values == \"-\"] = None\n",
    "        temp[\"xrefs_interaction\"] = values  \n",
    "    if column ==\"Annotations_a\":\n",
    "        values[values == \"-\"] = None\n",
    "        temp[\"annotations_a\"] = values    \n",
    "    if column ==\"Annotations_B\":\n",
    "        values[values == \"-\"] = None\n",
    "        temp[\"annotations_b\"] = values    \n",
    "    if column == \"Annotations_Interaction\":\n",
    "        values[values == \"-\"] = None\n",
    "        temp[\"annotations_interaction\"] = values    \n",
    "    if column ==\"Host_organism_taxid\":\n",
    "        a1, b1 = values.str.split(':', 1).str # separate string by :\n",
    "        temp[\"host_organism_taxid\"] = b1.str.replace(r\"\\(.*\\)\",\"\") # extract text outside the parenthesis\n",
    "        temp[\"host_organism_tax_name\"]=b1.str.replace(r'[\\(\\)\\d]+', '')# extract text inside parenthesis\n",
    "    if column ==\"parameters_Interaction\":\n",
    "        values[values == \"-\"] = None\n",
    "        temp[\"parameters_interaction\"] = values\n",
    "    if column == \"Creation_date\":\n",
    "        temp[\"creation_date\"] = values \n",
    "    if column == \"Update_date\":\n",
    "        temp[\"update_date\"] = values \n",
    "    if column == \"Negative\":\n",
    "        temp[\"negative\"] = values    \n",
    "    if column == \"irogida\":\n",
    "        temp[\"irogida\"] = values \n",
    "    if column == \"irogidb\":\n",
    "        temp[\"irogidb\"] = values \n",
    "    if column == \"irigid\":\n",
    "        temp[\"irigid\"] = values \n",
    "    if column == \"crogida\":\n",
    "        temp[\"crogida\"] = values \n",
    "    if column == \"crogidb\":\n",
    "        temp[\"crogidb\"] = values \n",
    "    if column == \"crigid\":\n",
    "        temp[\"crigid\"] = values    \n",
    "    if column == \"icrogida\":\n",
    "        temp[\"icrigida\"] = values    \n",
    "    if column == \"icrogidb\":\n",
    "        temp[\"icrigidb\"] = values    \n",
    "    if column == \"icrogid\":\n",
    "        temp[\"icrigid\"] = values    \n",
    "    if column == \"imex_id\":\n",
    "        temp[\"imex_id\"] = values\n",
    "    if column == \"edgetype\":\n",
    "        temp[\"edgetype\"] = values\n",
    "    if column == \"numParticipants\":\n",
    "        temp[\"numParticipants\"] = values\n",
    "    #if column == \"altA\":\n",
    "    #    a = str(values[0])\n",
    "    #    b = a.split(\"|\")\n",
    "    #    b_series = pd.Series(b)\n",
    "    #    c,d = b_series.str.split(':', 1).str\n",
    "    #    print(d)\n",
    "    #    break\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change delimeter and add column names\n",
    "ii_columns = ['uidA','uidB','altA','altB','aliasA','aliasB','method','author'\n",
    "              ,'pmids','taxa','taxb','interactionType','sourcedb','interactionIdentifier'\n",
    "              ,'confidence','expansion','biological_role_A','biological_role_B'\n",
    "              ,'experimental_role_A','experimental_role_B','interactor_type_A'\n",
    "              ,'interactor_type_B','xrefs_A','xrefs_B','xrefs_Interaction',\n",
    "              'Annotations_A','Annotations_B','Annotations_Interaction',\n",
    "              'Host_organism_taxid','parameters_Interaction','Creation_date',\n",
    "              'Update_date','Checksum_A','Checksum_B','Checksum_Interaction',\n",
    "              'Negative','OriginalReferenceA','OriginalReferenceB','FinalReferenceA'\n",
    "              ,'FinalReferenceB','MappingScoreA','MappingScoreB','irogida'\n",
    "              ,'irogidb','irigid','crogida','crogidb','crigid',\n",
    "              'icrogida','icrogidb','icrigid','imex_id','edgetype','numParticipants']\n",
    "df_irefindex = pd.read_csv('http://irefindex.org/download/irefindex/data/archive/release_15.0/psi_mitab/MITAB2.6/All.mitab.22012018.txt.zip',skiprows=1,delimiter='\\\\',header=None ,compression='zip',error_bad_lines=False)\n",
    "df_irefindex.columns = ii_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample=pd.read_csv(StringIO(''.join(l.replace('', ',') for l in open('stuff.csv'))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with zipfile.ZipFile('http://irefindex.org/download/irefindex/data/current/psi_mitab/MITAB2.6/All.mitab.22012018.txt.zip') as z:\n",
    "    with z.open('All.mitab.22012018.txt') as f:\n",
    "        for line in f:\n",
    "            print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib3\n",
    "\n",
    "http = urllib3.PoolManager()\n",
    "\n",
    "R = http.request('GET', \"http://irefindex.org/download/irefindex/data/current/psi_mitab/MITAB2.6/All.mitab.22012018.txt.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(R.read)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
